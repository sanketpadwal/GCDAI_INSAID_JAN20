{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sanketpadwal@gmail.com_DeepLearningFoundationProject.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLWP46P/4PZ8ziV+rltLLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanketpadwal/GCDAI_INSAID_JAN20/blob/main/Term7/sanketpadwal_gmail_com_DeepLearningFoundationProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUSzVnkrEnJQ"
      },
      "source": [
        "# Insaid Term Project - Deap Learning Foundation\n",
        "# **PREDICTING LOWEST PRODUCT PRICING USING ARTIFICIAL NUERAL NETWORK ALGORITHM**\n",
        "<img src=\"https://github.com/sanketpadwal/GCDAI_INSAID_JAN20/blob/main/Term4/Voice_Recognition1.jpeg?raw=true\" width=\"400\" height=\"250\" /><img src=\"https://github.com/sanketpadwal/GCDAI_INSAID_JAN20/blob/main/Term4/Voice_Recognition.jpeg?raw=true\" width=\"400\" height=\"250\" />\n",
        "\n",
        "           \n",
        "\n",
        "<a name = Section1></a>\n",
        "### **1. Introduction**\n",
        "---\n",
        "\n",
        "Voice recognition is the process of taking the spoken word as an input to a computer program. This process is important to virtual reality because it provides a fairly natural and intuitive way of controlling the simulation while allowing the user's hands to remain free. Voice recognition enables consumers to multitask by speaking directly to their Google Home, Amazon Alexa or other voice recognition technology. By using machine learning and sophisticated algorithms, voice recognition technology can quickly turn your spoken work into written text. Voice recognition technology also identifies a speaker and authenticates that he or she is indeed that individual. Unlike speech recognition, which identifies the words spoken, voice recognition analyzes countless patterns and elements that distinguish one person's voice from another. These days we expect personalization and want to search the internet without wasting time. Thatâ€™s the reason why Voice Search technology seems so promising.\n",
        "\n",
        "---\n",
        "<a name = Section2></a>\n",
        "### **2. Problem Statement**\n",
        "---\n",
        "The provided audio data cannot be understood by the models directly. To convert data into an understandable format feature extraction process is used. It is a process that explains most of the data but in an understandable way. Feature extraction is required for classification, prediction and recommendation algorithms incase data input in in audio format.\n",
        "'WarbleR R package' is designed for Acoustic analysis. The dataset which have acoustic parameters can be obtained with this analysis. Acoustic analysis of the voice depend upon parameter settings specific to sample characteristics such as intensity, duration, frequency and filtering. The acoustic properties of the voice and speech can be used to detect gender of the speaker. The dataset can be trained with different machine learning algorithms. In this project, SVM Classification method is used to detect(predict) the gender of voice inputs. Objective of this assessment is to identify the SVM kernel and hyper parameters for the better accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **Dataset:**\n",
        "Voice Gender - Gender recognition by voice and speech analysis.\n",
        "This database was created to identify a voice as male or female, based upon acoustic properties of the voice and speech. The dataset consists of 3168 recorded voice samples, collected from male and female speakers. The voice samples are pre-processed by acoustic analysis in R using the seewave and tuneR packages, with an analyzed frequency range of 0hz-280hz (human voice range) to derive 20 features.\n",
        "\n",
        "**Source:**<br> \n",
        "Github <br>https://raw.githubusercontent.com/sanketpadwal/GCDAI_INSAID_JAN20/main/Term4/voice.csv?_sm_au_=iVVHZq1W63S7vfBVL321jK0f1JH33\n",
        "\n",
        "\n",
        "**Attribute Information:**<br>\n",
        "1. **meanfreq:** mean frequency (in kHz)<br>\n",
        "2. **sd:** standard deviation of frequency <br>\n",
        "3. **median:** median frequency (in kHz)<br>\n",
        "4. **Q25:** first quantile (in kHz)<br>\n",
        "5. **Q75:** third quantile (in kHz)<br>\n",
        "6. **IQR:** interquantile range (in kHz)<br>\n",
        "7. **skew:** skewness (see note in specprop description)<br>\n",
        "8. **kurt** kurtosis (see note in specprop description)<br>\n",
        "9. **sp.ent:** spectral entropy<br>\n",
        "10. **sfm:** spectral flatness<br>\n",
        "11. **mode:** mode frequency<br>\n",
        "12. **centroid:** frequency centroid (see specprop)<br>\n",
        "13. **meanfun:** average of fundamental frequency measured across acoustic signal<br>\n",
        "14. **minfun:** minimum fundamental frequency measured across acoustic signal<br>\n",
        "15. **maxfun:** maximum fundamental frequency measured across acoustic signal<br>\n",
        "16. **meandom:** average of dominant frequency measured across acoustic signal<br>\n",
        "17. **mindom:** minimum of dominant frequency measured across acoustic signal<br>\n",
        "18. **maxdom:** maximum of dominant frequency measured across acoustic signal<br>\n",
        "19. **dfrange:** range of dominant frequency measured across acoustic signal<br>\n",
        "20. **modindx:** modulation index. Calculated as the accumulated absolute difference between<br>adjacent measurements of fundamental frequencies divided by the frequency range<br>\n",
        "21. **label:** male or female<br>\n",
        "\n",
        "### **Objective:**\n",
        " - Obtain an understanding on Support Vector Machine algorithm.\n",
        " - Fine tune algorithm to predict better accuracy with different kernel selections\n",
        " - Use of cross validation for the validation of results.\n",
        " - Perform Grid search technique to find the best parameter for SVM algorithm.\n",
        " - Compare accuracy with Decision Tree, Random Forest and Logistic Regressor models."
      ]
    }
  ]
}