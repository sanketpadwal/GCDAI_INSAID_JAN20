{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaggleDatasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmpwM3ALfoPkuTIkFxt6EY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanketpadwal/GCDAI_INSAID_JAN20/blob/main/Misc/KaggleDatasets_onColab/KaggleDatasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAxgESdcPN8J"
      },
      "source": [
        "# {\"username\": <ABC> ,\"key\": <key>}\n",
        "#https://gist.github.com/jayspeidell/d10b84b8d3da52df723beacc5b15cb27\n",
        "\n",
        "#remember to delete json file form gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOvaW8-bPZyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0083f8a3-5776-49ce-fada-62674145a1b3"
      },
      "source": [
        "%%time\n",
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16.2 ms, sys: 7.18 ms, total: 23.4 ms\n",
            "Wall time: 4.34 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsPkNzZH1wMh"
      },
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZRaBAhqM6kh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjvKPNDiQKVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59828486-ed2a-4ad3-8cfa-f82fd29bcf60"
      },
      "source": [
        "api_token = {\"username\":<ABC>,\"key\":<key>}\n",
        "!mkdir -p ~/.kaggle\n",
        "with open('kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3JePotkaZu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c55a55-c11f-4983-f442-901e2fe7795f"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                          title                                           size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  \n",
            "alexgude/california-traffic-collision-data-from-switrs       California Traffic Collision Data from SWITRS    1GB  2020-11-22 16:51:55            484  \n",
            "babyoda/women-entrepreneurship-and-labor-force               Women Entrepreneurship and Labor Force           1KB  2020-11-21 08:38:51           1591  \n",
            "szymonjanowski/internet-articles-data-with-users-engagement  Internet news data with readers engagement       3MB  2020-11-21 17:09:57            686  \n",
            "sakshigoyal7/credit-card-customers                           Credit Card customers                          379KB  2020-11-19 07:38:44           2924  \n",
            "imoore/2020-us-general-election-turnout-rates                2020 US General Election Turnout rates           4KB  2020-11-26 00:21:15           1029  \n",
            "afrniomelo/3w-dataset                                        3W Dataset - Undesirable events in oil wells   658MB  2020-11-21 21:22:49            104  \n",
            "patrickb1912/ipl-complete-dataset-20082020                   IPL Complete Dataset (2008-2020)                 1MB  2020-11-23 06:53:37            741  \n",
            "mrmorj/us-politicians-twitter-dataset                        US Politicians Twitter Dataset                  68KB  2020-11-23 09:54:05            258  \n",
            "arioboo/clumps-in-vela-galaxy-images                         Clumps in VELA galaxy images                     8MB  2020-11-23 13:42:09             85  \n",
            "shivamb/netflix-shows                                        Netflix Movies and TV Shows                    971KB  2020-01-20 07:33:56          66996  \n",
            "unanimad/us-election-2020                                    US Election 2020                               430KB  2020-11-29 14:53:02           9878  \n",
            "manchunhui/us-election-2020-tweets                           US Election 2020 Tweets                        353MB  2020-11-09 18:51:59           3879  \n",
            "sootersaalu/amazon-top-50-bestselling-books-2009-2019        Amazon Top 50 Bestselling Books 2009 - 2019     15KB  2020-10-13 09:39:21           6905  \n",
            "terenceshin/covid19s-impact-on-airport-traffic               COVID-19's Impact on Airport Traffic           106KB  2020-10-19 12:40:17           6214  \n",
            "nehaprabhavalkar/indian-food-101                             Indian Food 101                                  7KB  2020-09-30 06:23:43           8715  \n",
            "datasnaek/youtube-new                                        Trending YouTube Video Statistics              201MB  2019-06-03 00:56:47         118190  \n",
            "zynicide/wine-reviews                                        Wine Reviews                                    51MB  2017-11-27 17:08:04         121102  \n",
            "google/tinyquickdraw                                         QuickDraw Sketches                              11GB  2018-04-18 19:38:04           2556  \n",
            "karangadiya/fifa19                                           FIFA 19 complete player dataset                  2MB  2018-12-21 03:52:59         106867  \n",
            "datasnaek/chess                                              Chess Game Dataset (Lichess)                     3MB  2017-09-04 03:09:09          11530  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNz5aHF5aw1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc624fdb-0cd3-41da-a7c0-16a864f5f80e"
      },
      "source": [
        "!kaggle datasets list -s time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                        title                                               size  lastUpdated          downloadCount  \n",
            "---------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "ikarus777/best-artworks-of-all-time                        Best Artworks of All Time                            2GB  2019-03-02 09:21:51          11220  \n",
            "rohanrao/chai-time-data-science                            Chai Time Data Science | CTDS.Show                   3MB  2020-07-23 17:23:46            828  \n",
            "zurfer/rtb                                                 Real Time Bidding                                  138MB  2017-02-27 18:21:27           1648  \n",
            "girardi69/marathon-time-predictions                        Marathon time Predictions                            3KB  2017-05-13 09:56:01           1656  \n",
            "szrlee/stock-time-series-20050101-to-20171231              DJIA 30 Stock Time Series                            3MB  2018-01-03 08:29:18          14846  \n",
            "aashita/nyt-comments                                       New York Times Comments                            480MB  2018-05-02 05:05:20          10052  \n",
            "therohk/ireland-historical-news                            Irish Times - Waxy-Wany News                        49MB  2020-09-08 20:34:05           2800  \n",
            "sumanthvrao/daily-climate-time-series-data                 Daily Climate time series data                      22KB  2019-08-23 09:22:09           3704  \n",
            "bls/american-time-use-survey                               American Time Use Survey                           249MB  2017-06-15 16:32:54           2162  \n",
            "atulanandjha/national-stock-exchange-time-series           National Stock Exchange : Time Series               29KB  2019-12-02 23:49:29           1047  \n",
            "census/population-time-series-data                         Population Time Series Data                          8KB  2019-12-06 09:17:36           2698  \n",
            "kazanova/sentiment140                                      Sentiment140 dataset with 1.6 million tweets        81MB  2017-09-13 22:43:19          43095  \n",
            "volpatto/temperature-timeseries-for-some-brazilian-cities  Temperature Time-Series for some Brazilian cities   27KB  2019-12-08 23:15:09           2113  \n",
            "cdeotte/malware-timestamps                                 Malware Timestamps                                 416KB  2019-01-17 14:19:25           1043  \n",
            "crowdflower/twitter-airline-sentiment                      Twitter US Airline Sentiment                         3MB  2019-10-16 00:04:05          47116  \n",
            "cjroth/chronist                                            Emotion, Aging, and Sentiment Over Time             13MB  2017-02-12 22:44:03           1440  \n",
            "htagholdings/property-sales                                House Property Sales Time Series                   162KB  2019-08-12 10:07:10           2377  \n",
            "bittlingmayer/amazonreviews                                Amazon Reviews for Sentiment Analysis              493MB  2019-11-18 02:50:34          30810  \n",
            "jguerreiro/running                                         Top Running Times                                  252KB  2017-05-19 21:54:30            783  \n",
            "notgibs/500-greatest-albums-of-all-time-rolling-stone      Rolling Stone's 500 Greatest Albums of All Time     13KB  2017-01-06 02:39:49           1946  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYdGaijhbSBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b780d33-54a5-4321-c816-504f64ca62ce"
      },
      "source": [
        "%%time\n",
        "!kaggle datasets download -d rohanrao/chai-time-data-science -p /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading chai-time-data-science.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 89.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehd3RoiSbgfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14499f1d-2bb7-46e0-850a-ac1987d68d3d"
      },
      "source": [
        "%%time\n",
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  chai-time-data-science.zip\n",
            "  inflating: Anchor Thumbnail Types.csv  \n",
            "  inflating: Cleaned Subtitles/E1.csv  \n",
            "  inflating: Cleaned Subtitles/E10.csv  \n",
            "  inflating: Cleaned Subtitles/E11.csv  \n",
            "  inflating: Cleaned Subtitles/E12.csv  \n",
            "  inflating: Cleaned Subtitles/E13.csv  \n",
            "  inflating: Cleaned Subtitles/E14.csv  \n",
            "  inflating: Cleaned Subtitles/E15.csv  \n",
            "  inflating: Cleaned Subtitles/E16.csv  \n",
            "  inflating: Cleaned Subtitles/E17.csv  \n",
            "  inflating: Cleaned Subtitles/E18.csv  \n",
            "  inflating: Cleaned Subtitles/E19.csv  \n",
            "  inflating: Cleaned Subtitles/E2.csv  \n",
            "  inflating: Cleaned Subtitles/E20.csv  \n",
            "  inflating: Cleaned Subtitles/E21.csv  \n",
            "  inflating: Cleaned Subtitles/E22.csv  \n",
            "  inflating: Cleaned Subtitles/E23.csv  \n",
            "  inflating: Cleaned Subtitles/E24.csv  \n",
            "  inflating: Cleaned Subtitles/E25.csv  \n",
            "  inflating: Cleaned Subtitles/E26.csv  \n",
            "  inflating: Cleaned Subtitles/E27.csv  \n",
            "  inflating: Cleaned Subtitles/E28.csv  \n",
            "  inflating: Cleaned Subtitles/E29.csv  \n",
            "  inflating: Cleaned Subtitles/E3.csv  \n",
            "  inflating: Cleaned Subtitles/E30.csv  \n",
            "  inflating: Cleaned Subtitles/E31.csv  \n",
            "  inflating: Cleaned Subtitles/E32.csv  \n",
            "  inflating: Cleaned Subtitles/E33.csv  \n",
            "  inflating: Cleaned Subtitles/E34.csv  \n",
            "  inflating: Cleaned Subtitles/E35.csv  \n",
            "  inflating: Cleaned Subtitles/E36.csv  \n",
            "  inflating: Cleaned Subtitles/E37.csv  \n",
            "  inflating: Cleaned Subtitles/E38.csv  \n",
            "  inflating: Cleaned Subtitles/E39.csv  \n",
            "  inflating: Cleaned Subtitles/E40.csv  \n",
            "  inflating: Cleaned Subtitles/E41.csv  \n",
            "  inflating: Cleaned Subtitles/E42.csv  \n",
            "  inflating: Cleaned Subtitles/E43.csv  \n",
            "  inflating: Cleaned Subtitles/E44.csv  \n",
            "  inflating: Cleaned Subtitles/E45.csv  \n",
            "  inflating: Cleaned Subtitles/E46.csv  \n",
            "  inflating: Cleaned Subtitles/E47.csv  \n",
            "  inflating: Cleaned Subtitles/E48.csv  \n",
            "  inflating: Cleaned Subtitles/E49.csv  \n",
            "  inflating: Cleaned Subtitles/E5.csv  \n",
            "  inflating: Cleaned Subtitles/E50.csv  \n",
            "  inflating: Cleaned Subtitles/E51.csv  \n",
            "  inflating: Cleaned Subtitles/E52.csv  \n",
            "  inflating: Cleaned Subtitles/E53.csv  \n",
            "  inflating: Cleaned Subtitles/E54.csv  \n",
            "  inflating: Cleaned Subtitles/E55.csv  \n",
            "  inflating: Cleaned Subtitles/E56.csv  \n",
            "  inflating: Cleaned Subtitles/E57.csv  \n",
            "  inflating: Cleaned Subtitles/E58.csv  \n",
            "  inflating: Cleaned Subtitles/E59.csv  \n",
            "  inflating: Cleaned Subtitles/E6.csv  \n",
            "  inflating: Cleaned Subtitles/E60.csv  \n",
            "  inflating: Cleaned Subtitles/E61.csv  \n",
            "  inflating: Cleaned Subtitles/E62.csv  \n",
            "  inflating: Cleaned Subtitles/E63.csv  \n",
            "  inflating: Cleaned Subtitles/E64.csv  \n",
            "  inflating: Cleaned Subtitles/E65.csv  \n",
            "  inflating: Cleaned Subtitles/E66.csv  \n",
            "  inflating: Cleaned Subtitles/E67.csv  \n",
            "  inflating: Cleaned Subtitles/E68.csv  \n",
            "  inflating: Cleaned Subtitles/E69.csv  \n",
            "  inflating: Cleaned Subtitles/E7.csv  \n",
            "  inflating: Cleaned Subtitles/E70.csv  \n",
            "  inflating: Cleaned Subtitles/E71.csv  \n",
            "  inflating: Cleaned Subtitles/E72.csv  \n",
            "  inflating: Cleaned Subtitles/E73.csv  \n",
            "  inflating: Cleaned Subtitles/E74.csv  \n",
            "  inflating: Cleaned Subtitles/E75.csv  \n",
            "  inflating: Cleaned Subtitles/E8.csv  \n",
            "  inflating: Cleaned Subtitles/E9.csv  \n",
            "  inflating: Description.csv         \n",
            "  inflating: Episodes.csv            \n",
            "  inflating: Raw Subtitles/E1.txt    \n",
            "  inflating: Raw Subtitles/E10.txt   \n",
            "  inflating: Raw Subtitles/E11.txt   \n",
            "  inflating: Raw Subtitles/E12.txt   \n",
            "  inflating: Raw Subtitles/E13.txt   \n",
            "  inflating: Raw Subtitles/E14.txt   \n",
            "  inflating: Raw Subtitles/E15.txt   \n",
            "  inflating: Raw Subtitles/E16.txt   \n",
            "  inflating: Raw Subtitles/E17.txt   \n",
            "  inflating: Raw Subtitles/E18.txt   \n",
            "  inflating: Raw Subtitles/E19.txt   \n",
            "  inflating: Raw Subtitles/E2.txt    \n",
            "  inflating: Raw Subtitles/E20.txt   \n",
            "  inflating: Raw Subtitles/E21.txt   \n",
            "  inflating: Raw Subtitles/E22.txt   \n",
            "  inflating: Raw Subtitles/E23.txt   \n",
            "  inflating: Raw Subtitles/E24.txt   \n",
            "  inflating: Raw Subtitles/E25.txt   \n",
            "  inflating: Raw Subtitles/E26.txt   \n",
            "  inflating: Raw Subtitles/E27.txt   \n",
            "  inflating: Raw Subtitles/E28.txt   \n",
            "  inflating: Raw Subtitles/E29.txt   \n",
            "  inflating: Raw Subtitles/E3.txt    \n",
            "  inflating: Raw Subtitles/E30.txt   \n",
            "  inflating: Raw Subtitles/E31.txt   \n",
            "  inflating: Raw Subtitles/E32.txt   \n",
            "  inflating: Raw Subtitles/E33.txt   \n",
            "  inflating: Raw Subtitles/E34.txt   \n",
            "  inflating: Raw Subtitles/E35.txt   \n",
            "  inflating: Raw Subtitles/E36.txt   \n",
            "  inflating: Raw Subtitles/E37.txt   \n",
            "  inflating: Raw Subtitles/E38.txt   \n",
            "  inflating: Raw Subtitles/E39.txt   \n",
            "  inflating: Raw Subtitles/E40.txt   \n",
            "  inflating: Raw Subtitles/E41.txt   \n",
            "  inflating: Raw Subtitles/E42.txt   \n",
            "  inflating: Raw Subtitles/E43.txt   \n",
            "  inflating: Raw Subtitles/E44.txt   \n",
            "  inflating: Raw Subtitles/E45.txt   \n",
            "  inflating: Raw Subtitles/E46.txt   \n",
            "  inflating: Raw Subtitles/E47.txt   \n",
            "  inflating: Raw Subtitles/E48.txt   \n",
            "  inflating: Raw Subtitles/E49.txt   \n",
            "  inflating: Raw Subtitles/E5.txt    \n",
            "  inflating: Raw Subtitles/E50.txt   \n",
            "  inflating: Raw Subtitles/E51.txt   \n",
            "  inflating: Raw Subtitles/E52.txt   \n",
            "  inflating: Raw Subtitles/E53.txt   \n",
            "  inflating: Raw Subtitles/E54.txt   \n",
            "  inflating: Raw Subtitles/E55.txt   \n",
            "  inflating: Raw Subtitles/E56.txt   \n",
            "  inflating: Raw Subtitles/E57.txt   \n",
            "  inflating: Raw Subtitles/E58.txt   \n",
            "  inflating: Raw Subtitles/E59.txt   \n",
            "  inflating: Raw Subtitles/E6.txt    \n",
            "  inflating: Raw Subtitles/E60.txt   \n",
            "  inflating: Raw Subtitles/E61.txt   \n",
            "  inflating: Raw Subtitles/E62.txt   \n",
            "  inflating: Raw Subtitles/E63.txt   \n",
            "  inflating: Raw Subtitles/E64.txt   \n",
            "  inflating: Raw Subtitles/E65.txt   \n",
            "  inflating: Raw Subtitles/E66.txt   \n",
            "  inflating: Raw Subtitles/E67.txt   \n",
            "  inflating: Raw Subtitles/E68.txt   \n",
            "  inflating: Raw Subtitles/E69.txt   \n",
            "  inflating: Raw Subtitles/E7.txt    \n",
            "  inflating: Raw Subtitles/E70.txt   \n",
            "  inflating: Raw Subtitles/E71.txt   \n",
            "  inflating: Raw Subtitles/E72.txt   \n",
            "  inflating: Raw Subtitles/E73.txt   \n",
            "  inflating: Raw Subtitles/E74.txt   \n",
            "  inflating: Raw Subtitles/E75.txt   \n",
            "  inflating: Raw Subtitles/E8.txt    \n",
            "  inflating: Raw Subtitles/E9.txt    \n",
            "  inflating: Results.csv             \n",
            "  inflating: YouTube Thumbnail Types.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO5gKzeehAtG"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"Results.csv\")\n",
        "# train = pd.read_csv(\"train.csv\")\n",
        "# test = pd.read_csv(\"test.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "rikQsFvT3Wd-",
        "outputId": "bd7780b1-4071-4093-deb1-ed39296abd44"
      },
      "source": [
        "%%time\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39 µs, sys: 0 ns, total: 39 µs\n",
            "Wall time: 42 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Notebook</th>\n",
              "      <th>Author</th>\n",
              "      <th>Presentation</th>\n",
              "      <th>Storytelling</th>\n",
              "      <th>Visualizations</th>\n",
              "      <th>Insights</th>\n",
              "      <th>Innovation</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Making perfect \"Chai\" and other tales :)</td>\n",
              "      <td>thedatabeast</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>88.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fun with Chai Time Data Science Show</td>\n",
              "      <td>ambarish</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>76.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What's this? Chai and DataScience?</td>\n",
              "      <td>rahulgulia</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Does Twitter Chirp Chai?</td>\n",
              "      <td>vrindaprabhu</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1 year of CTDS Journey and what we infer</td>\n",
              "      <td>vinothsuku</td>\n",
              "      <td>13.5</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>15.5</td>\n",
              "      <td>12.5</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CTDS - Subtitles exploration</td>\n",
              "      <td>crazydiv</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.5</td>\n",
              "      <td>69.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CTDS: answering the \"what...\" question differe...</td>\n",
              "      <td>neomatrix369</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Journey of CTDS.show through Visuals</td>\n",
              "      <td>anshuls235</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>To Tea, or Not to Tea</td>\n",
              "      <td>sahiljuneja</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Analysing CTDS show- Views and Reach</td>\n",
              "      <td>kurianbenoy</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>60.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Analysing Sanyam's Great Chai Time Shows</td>\n",
              "      <td>gsdeepakkumar</td>\n",
              "      <td>12.5</td>\n",
              "      <td>12.5</td>\n",
              "      <td>12.5</td>\n",
              "      <td>10.5</td>\n",
              "      <td>10.5</td>\n",
              "      <td>58.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Chai Aur Biskoot</td>\n",
              "      <td>universalastro</td>\n",
              "      <td>9.5</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>55.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Insights on Chai Time Data Science</td>\n",
              "      <td>vpkprasanna</td>\n",
              "      <td>10.5</td>\n",
              "      <td>10.5</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Analyzing CTDS - with d3.js!</td>\n",
              "      <td>nxrprime</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Creative Space on Data Science with Sanyam Bhu...</td>\n",
              "      <td>sagargupta831</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>48.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Understanding the CTDS host(Sanyam Bhutani)</td>\n",
              "      <td>kurianbenoy</td>\n",
              "      <td>9.5</td>\n",
              "      <td>7.5</td>\n",
              "      <td>10.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>CTDS - Data Analysis</td>\n",
              "      <td>nishant173</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>44.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CTDS insights and analysis</td>\n",
              "      <td>beekiran</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>40.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>How we got our Great Chai Time</td>\n",
              "      <td>marshal02</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>39.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>CTDS insights</td>\n",
              "      <td>nilimajauhari</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Chai time sentence transformer episode clustering</td>\n",
              "      <td>mayeesha</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>13.0</td>\n",
              "      <td>38.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Analysis over Chai</td>\n",
              "      <td>krrai77</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>chai_time_data_science</td>\n",
              "      <td>pawan2905</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>CTDS [In-Depth Analysis and Visualization]</td>\n",
              "      <td>aviralpamecha</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>31.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Exploring CTDS</td>\n",
              "      <td>sonujha090</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Text Processing, Similarity and Sentiment Anal...</td>\n",
              "      <td>aviralpamecha</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Notebook  ... Total\n",
              "0            Making perfect \"Chai\" and other tales :)  ...  88.0\n",
              "1                Fun with Chai Time Data Science Show  ...  76.5\n",
              "2                  What's this? Chai and DataScience?  ...  71.0\n",
              "3                            Does Twitter Chirp Chai?  ...  70.0\n",
              "4            1 year of CTDS Journey and what we infer  ...  70.0\n",
              "5                        CTDS - Subtitles exploration  ...  69.5\n",
              "6   CTDS: answering the \"what...\" question differe...  ...  66.0\n",
              "7                Journey of CTDS.show through Visuals  ...  65.5\n",
              "8                               To Tea, or Not to Tea  ...  62.0\n",
              "9                Analysing CTDS show- Views and Reach  ...  60.5\n",
              "10           Analysing Sanyam's Great Chai Time Shows  ...  58.5\n",
              "11                                   Chai Aur Biskoot  ...  55.0\n",
              "12                 Insights on Chai Time Data Science  ...  50.0\n",
              "13                       Analyzing CTDS - with d3.js!  ...  49.0\n",
              "14  Creative Space on Data Science with Sanyam Bhu...  ...  48.0\n",
              "15        Understanding the CTDS host(Sanyam Bhutani)  ...  46.0\n",
              "16                               CTDS - Data Analysis  ...  44.5\n",
              "17                         CTDS insights and analysis  ...  40.5\n",
              "18                     How we got our Great Chai Time  ...  39.5\n",
              "19                                      CTDS insights  ...  39.0\n",
              "20  Chai time sentence transformer episode clustering  ...  38.5\n",
              "21                                 Analysis over Chai  ...  38.0\n",
              "22                             chai_time_data_science  ...  34.0\n",
              "23         CTDS [In-Depth Analysis and Visualization]  ...  31.5\n",
              "24                                     Exploring CTDS  ...  25.0\n",
              "25  Text Processing, Similarity and Sentiment Anal...  ...  18.5\n",
              "\n",
              "[26 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}
